{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9069065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\feature_engine\\datetime\\datetime.py:347: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\feature_engine\\datetime\\datetime.py:347: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['preprocessor.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import joblib\n",
    "import pickle\n",
    "import optuna\n",
    "import streamlit as st\n",
    "\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from feature_engine.encoding import RareLabelEncoder, MeanEncoder, CountFrequencyEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# preprocessing operations\n",
    "air_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t(\"grouper\", RareLabelEncoder(tol=0.1, replace_with=\"Other\", n_categories=2)),\n",
    "\t(\"encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "#doj\n",
    "feature_to_extract = [\"month\", \"week\", \"day_of_week\", \"day_of_year\"]\n",
    "\n",
    "doj_transformer = Pipeline(steps=[\n",
    "\t(\"dt\", DatetimeFeatures(features_to_extract=feature_to_extract, yearfirst=True, format=\"mixed\")),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "# source & destination\n",
    "location_pipe1 = Pipeline(steps=[\n",
    "\t(\"grouper\", RareLabelEncoder(tol=0.1, replace_with=\"Other\", n_categories=2)),\n",
    "\t(\"encoder\", MeanEncoder()),\n",
    "\t(\"scaler\", PowerTransformer())\n",
    "])\n",
    "\n",
    "def is_north(X):\n",
    "\tcolumns = X.columns.to_list()\n",
    "\tnorth_cities = [\"Delhi\", \"Kolkata\", \"Mumbai\", \"New Delhi\"]\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"{col}_is_north\": X.loc[:, col].isin(north_cities).astype(int)\n",
    "\t\t\tfor col in columns\n",
    "\t\t})\n",
    "\t\t.drop(columns=columns)\n",
    "\t)\n",
    "\n",
    "location_transformer = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", location_pipe1),\n",
    "\t(\"part2\", FunctionTransformer(func=is_north))\n",
    "])\n",
    "\n",
    "# dep_time & arrival_time\n",
    "time_pipe1 = Pipeline(steps=[\n",
    "\t(\"dt\", DatetimeFeatures(features_to_extract=[\"hour\", \"minute\"])),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "def part_of_day(X, morning=4, noon=12, eve=16, night=20):\n",
    "\tcolumns = X.columns.to_list()\n",
    "\tX_temp = X.assign(**{\n",
    "\t\tcol: pd.to_datetime(X.loc[:, col], dayfirst=False, format=\"mixed\").dt.hour\n",
    "\t\tfor col in columns\n",
    "\t})\n",
    "\n",
    "\treturn (\n",
    "\t\tX_temp\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"{col}_part_of_day\": np.select(\n",
    "\t\t\t\t[X_temp.loc[:, col].between(morning, noon, inclusive=\"left\"),\n",
    "\t\t\t\t X_temp.loc[:, col].between(noon, eve, inclusive=\"left\"),\n",
    "\t\t\t\t X_temp.loc[:, col].between(eve, night, inclusive=\"left\")],\n",
    "\t\t\t\t[\"morning\", \"afternoon\", \"evening\"],\n",
    "\t\t\t\tdefault=\"night\"\n",
    "\t\t\t)\n",
    "\t\t\tfor col in columns\n",
    "\t\t})\n",
    "\t\t.drop(columns=columns)\n",
    "\t)\n",
    "\n",
    "time_pipe2 = Pipeline(steps=[\n",
    "\t(\"part\", FunctionTransformer(func=part_of_day)),\n",
    "\t(\"encoder\", CountFrequencyEncoder()),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "time_transformer = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", time_pipe1),\n",
    "\t(\"part2\", time_pipe2)\n",
    "])\n",
    "\n",
    "# duration\n",
    "class RBFPercentileSimilarity(BaseEstimator, TransformerMixin):\n",
    "\tdef __init__(self, variables=None, percentiles=[0.25, 0.5, 0.75], gamma=0.1):\n",
    "\t\tself.variables = variables\n",
    "\t\tself.percentiles = percentiles\n",
    "\t\tself.gamma = gamma\n",
    "\n",
    "\n",
    "\tdef fit(self, X, y=None):\n",
    "\t\tif not self.variables:\n",
    "\t\t\tself.variables = X.select_dtypes(include=\"number\").columns.to_list()\n",
    "\n",
    "\t\tself.reference_values_ = {\n",
    "\t\t\tcol: (\n",
    "\t\t\t\tX\n",
    "\t\t\t\t.loc[:, col]\n",
    "\t\t\t\t.quantile(self.percentiles)\n",
    "\t\t\t\t.values\n",
    "\t\t\t\t.reshape(-1, 1)\n",
    "\t\t\t)\n",
    "\t\t\tfor col in self.variables\n",
    "\t\t}\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\n",
    "\tdef transform(self, X):\n",
    "\t\tobjects = []\n",
    "\t\tfor col in self.variables:\n",
    "\t\t\tcolumns = [f\"{col}_rbf_{int(percentile * 100)}\" for percentile in self.percentiles]\n",
    "\t\t\tobj = pd.DataFrame(\n",
    "\t\t\t\tdata=rbf_kernel(X.loc[:, [col]], Y=self.reference_values_[col], gamma=self.gamma),\n",
    "\t\t\t\tcolumns=columns\n",
    "\t\t\t)\n",
    "\t\t\tobjects.append(obj)\n",
    "\t\treturn pd.concat(objects, axis=1)\n",
    "\t\n",
    "\n",
    "def duration_category(X, short=180, med=400):\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(duration_cat=np.select([X.duration.lt(short),\n",
    "\t\t\t\t\t\t\t\t\t\tX.duration.between(short, med, inclusive=\"left\")],\n",
    "\t\t\t\t\t\t\t\t\t   [\"short\", \"medium\"],\n",
    "\t\t\t\t\t\t\t\t\t   default=\"long\"))\n",
    "\t\t.drop(columns=\"duration\")\n",
    "\t)\n",
    "\n",
    "def is_over(X, value=1000):\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"duration_over_{value}\": X.duration.ge(value).astype(int)\n",
    "\t\t})\n",
    "\t\t.drop(columns=\"duration\")\n",
    "\t)\n",
    "\n",
    "duration_pipe1 = Pipeline(steps=[\n",
    "\t(\"rbf\", RBFPercentileSimilarity()),\n",
    "\t(\"scaler\", PowerTransformer())\n",
    "])\n",
    "\n",
    "duration_pipe2 = Pipeline(steps=[\n",
    "\t(\"cat\", FunctionTransformer(func=duration_category)),\n",
    "\t(\"encoder\", OrdinalEncoder(categories=[[\"short\", \"medium\", \"long\"]]))\n",
    "])\n",
    "\n",
    "duration_union = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", duration_pipe1),\n",
    "\t(\"part2\", duration_pipe2),\n",
    "\t(\"part3\", FunctionTransformer(func=is_over)),\n",
    "\t(\"part4\", StandardScaler())\n",
    "])\n",
    "\n",
    "duration_transformer = Pipeline(steps=[\n",
    "\t(\"outliers\", Winsorizer(capping_method=\"iqr\", fold=1.5)),\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "\t(\"union\", duration_union)\n",
    "])\n",
    "\n",
    "# total_stops\n",
    "def is_direct(X):\n",
    "\treturn X.assign(is_direct_flight=X.total_stops.eq(0).astype(int))\n",
    "\n",
    "\n",
    "total_stops_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t(\"\", FunctionTransformer(func=is_direct))\n",
    "])\n",
    "\n",
    "# additional_info\n",
    "info_pipe1 = Pipeline(steps=[\n",
    "\t(\"group\", RareLabelEncoder(tol=0.1, n_categories=2, replace_with=\"Other\")),\n",
    "\t(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "def have_info(X):\n",
    "\treturn X.assign(additional_info=X.additional_info.ne(\"No Info\").astype(int))\n",
    "\n",
    "info_union = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", info_pipe1),\n",
    "\t(\"part2\", FunctionTransformer(func=have_info))\n",
    "])\n",
    "\n",
    "info_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "\t(\"union\", info_union)\n",
    "])\n",
    "\n",
    "# column transformer\n",
    "column_transformer = ColumnTransformer(transformers=[\n",
    "\t(\"air\", air_transformer, [\"airline\"]),\n",
    "\t(\"doj\", doj_transformer, [\"date_of_journey\"]),\n",
    "\t(\"location\", location_transformer, [\"source\", 'destination']),\n",
    "\t(\"time\", time_transformer, [\"dep_time\", \"arrival_time\"]),\n",
    "\t(\"dur\", duration_transformer, [\"duration\"]),\n",
    "\t(\"stops\", total_stops_transformer, [\"total_stops\"]),\n",
    "\t(\"info\", info_transformer, [\"additional_info\"])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# feature selector\n",
    "estimator = RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)\n",
    "\n",
    "selector = SelectBySingleFeaturePerformance(\n",
    "\testimator=estimator,\n",
    "\tscoring=\"r2\",\n",
    "\tthreshold=0.1\n",
    ") \n",
    "\n",
    "# preprocessor\n",
    "preprocessor = Pipeline(steps=[\n",
    "\t(\"ct\", column_transformer),\n",
    "\t(\"selector\", selector)\n",
    "])\n",
    "\n",
    "# Reading the training data\n",
    "file_path = r\"C:\\Users\\User\\OneDrive\\Desktop\\Flight-Price-Prediction\\Data\\train.csv\"\n",
    "\n",
    "train = pd.read_csv(file_path)\n",
    "\n",
    "X_train = train.drop(columns=\"price\")\n",
    "y_train = train.price.copy()\n",
    "\n",
    "# Fit and save the preprocessor\n",
    "preprocessor.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159700d2",
   "metadata": {},
   "source": [
    "# Web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09b630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(\n",
    "    page_title = \"Flight Prices Prediction\",\n",
    "    page_icon = \"✈️\",\n",
    "    layout = \"wide\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2692ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 20:27:37.444 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\User\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title(\"Flight Prices Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da86312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 20:27:37.469 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "airline = st.selectbox(\"Airline:\",\n",
    "                      options=X_train.airline.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d5dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "doj = st.date_input(\"Date of Journey : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8484d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = st.selectbox(\"Source:\",\n",
    "                      options=X_train.source.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e073a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = st.selectbox(\"Destination:\",\n",
    "                      options=X_train.destination.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1637a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_time = st.time_input(\"Departure time : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1233284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_time = st.time_input(\"Arrival time : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2997c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = st.number_input(\n",
    "    \"Duration (minutes):\",\n",
    "    step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10bb8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stops = st.number_input(\n",
    "    \"Total stops :\",\n",
    "    step=1,\n",
    "    min_value = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5d1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info = st.selectbox(\n",
    "    \"Additional information : \",\n",
    "    options=X_train.additional_info.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "116382e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = pd.DataFrame(dict(\n",
    "    airline=[airline],\n",
    "    date_of_journey=[doj],\n",
    "    source=[src],\n",
    "    destination=[destination],\n",
    "    dep_time=[dep_time],\n",
    "    arrival_time=[arrival_time],\n",
    "    duration=[duration],\n",
    "    total_stops=[total_stops],\n",
    "    additional_info=[additional_info]\n",
    ")).astype({\n",
    "    col : \"str\"\n",
    "    for col in [\"date_of_journey\", \"arrival_time\", \"dep_time\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50cb8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.button(\"Predict\"):\n",
    "    saved_preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "    x_new_transformed = saved_preprocessor.transform(x_new)\n",
    "    \n",
    "    with open(\"xgboost-best_model.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    x_new_xgb = xgb.DMatrix(x_new_transformed)\n",
    "    pred = model.predict(x_new_xgb)[0]\n",
    "    st.info(f\"The predicted price is {pred:,.0f} INR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb8296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
